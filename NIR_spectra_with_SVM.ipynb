{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_CsjzuBMvUK"
   },
   "source": [
    "# Estimating a continious variable from a near-infrared spectra\n",
    "\n",
    "Near Infrared spectroscopy is a powerful technique , used to define nutrient content of food samples when chemical analysis in not applicable. The project considers use of SVM algorithm for regression along with Savitsky-Golay filter for interpretation of spectral modifications into the information regarding the composition of the given sample. SVM is characterized by unique loss function, which is used to penalize errors that are greater than threshold. Such loss functions leads to the sparse representation of the decision rule, giving significant algorithmic and representational advantages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_1V_leWMvUL"
   },
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDA9XVulMvUN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdEe1wTQrJh6"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('spectra-animal-feed.csv', index_col=0, header=None, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "zWvWkJLJMvUR",
    "outputId": "a93420a8-15ca-4eae-8e91-d1e740bda383"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tfo8qLmwMvUc"
   },
   "source": [
    "We have much more data now, so we will not do feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyJiktvHMvUd"
   },
   "outputs": [],
   "source": [
    "df.columns = ['target']+[1120+2*(i-1) for i in range(1,681)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "Eu6wRpJVLMKj",
    "outputId": "3cf7c3d4-83b3-446e-9f1d-322237f8cc53"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "7JWruupHMvUn",
    "outputId": "0011b32e-6b54-4650-aa79-34aa766045b3"
   },
   "outputs": [],
   "source": [
    "plt.hist(df.iloc[:,0], bins=30);\n",
    "plt.title('Distribution of the protein % range')\n",
    "plt.xlabel('Title')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35eO3Q6C2x46"
   },
   "source": [
    "Here is an example of the spectra in your data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "DDrygwvK2iEk",
    "outputId": "106ecea0-19b0-4d13-f063-528b2b4f4bc4"
   },
   "outputs": [],
   "source": [
    "plt.plot(df.iloc[0,1:]);\n",
    "plt.xlabel('Wavelength (nm)');\n",
    "plt.ylabel('Absorbance');\n",
    "plt.title('NIR spectra');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJKopg3JuKrd"
   },
   "source": [
    "# Create holdout dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JL9mAHoSs4_P"
   },
   "source": [
    "We can easily create a holdout dataset with scikit functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iASzE68Os02G"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df.iloc[:,1:].values\n",
    "y=df.iloc[:,0].values\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "d1X = savgol_filter(X,25,polyorder = 5, deriv = 1)\n",
    "Xstd = StandardScaler().fit_transform(d1X[:,:])\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xstd, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7XGreswMvVM"
   },
   "source": [
    "# Baseline model: SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POEUqZwaMvVW"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Try this to use grid search\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Tuning of parameters for regression by cross-validation\n",
    "K = 10               # Number of cross validations\n",
    "\n",
    "# Parameters for tuning\n",
    "parameters = [{'kernel': ['rbf'], 'gamma': [0.1,0.01, 0.001],'C': [10 ,50, 100]}]\n",
    "print(\"Tuning hyper-parameters\")\n",
    "svr = GridSearchCV(SVR(epsilon = 0.01), parameters, cv = K)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Checking the score for all parameters\n",
    "print(\"Grid scores on training set:\")\n",
    "means = svr.cv_results_['mean_test_score']\n",
    "stds = svr.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, svr.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "y_min, y_max = min(y_test), max(y_test)\n",
    "y_pred = svr.predict(X_test)\n",
    "line = np.linspace(y_min, y_max, len(y_test))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(line, line, 'r')\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.xlim(y_min, y_max)\n",
    "plt.ylim(y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "z9E5g8SPyxnk",
    "outputId": "f1a9f4a4-cf09-4147-9c77-d176702ddb8f"
   },
   "outputs": [],
   "source": [
    "#Trying the model with already tuned parameters \n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Parameters for tuning\n",
    "svr_1 = SVR(epsilon = 0.01, gamma = 0.001, C = 100, kernel = 'rbf')\n",
    "svr_1.fit(X_train, y_train)\n",
    "print(svr_1.score(X_test, y_test))\n",
    "y_min, y_max = min(y_test), max(y_test)\n",
    "y_pred = svr_1.predict(X_test)\n",
    "line = np.linspace(y_min, y_max, len(y_test))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(line, line, 'r')\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.xlim(y_min, y_max)\n",
    "plt.ylim(y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Hclj2ESv-mRJ",
    "outputId": "4c20b0b3-07c4-4701-d7b3-e9c557bb953e"
   },
   "outputs": [],
   "source": [
    "#The holdout set is unfortunately not for public disclosure; so, while keeping the code for it, I can't share the results from it.\n",
    "\n",
    "#df_pred = pd.read_csv('holdout.csv', header=None)\n",
    "#print(df_pred)\n",
    "#X_forpred = df_pred.iloc[:,:].values\n",
    "#X_forpred = savgol_filter(X_forpred,25,polyorder = 5, deriv = 1)\n",
    "#X_forpred = StandardScaler().fit_transform(X_forpred[:,:])\n",
    "\n",
    "#svr_2 = SVR(epsilon = 0.01, gamma = 0.001, C = 100, kernel = 'rbf')\n",
    "#svr_2.fit(Xstd,y)\n",
    "#y_forpredwithwholetrainingset = svr_2.predict(X_forpred) \n",
    "#print(y_forpredwithwholetrainingset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXcBalprXFkI"
   },
   "outputs": [],
   "source": [
    "#checking the feature importances\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from copy import copy\n",
    "def cv_importances(model, X_train, y_train, k=1):\n",
    "    \"\"\"\n",
    "    Compute permutation feature importances for scikit-learn models using\n",
    "    k-fold cross-validation (default k=3).\n",
    "    Given a Classifier or Regressor in model\n",
    "    and training X and y data, return a data frame with columns\n",
    "    Feature and Importance sorted in reverse order by importance.\n",
    "    Cross-validation observations are taken from X_train, y_train.\n",
    "    The model.score() method is called to measure accuracy drops.\n",
    "    return: A data frame with Feature, Importance columns\n",
    "    SAMPLE CODE\n",
    "    rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "    X_train, y_train = ..., ...\n",
    "    rf.fit(X_train, y_train)\n",
    "    imp = cv_importances(rf, X_train, y_train)\n",
    "    \"\"\"\n",
    "    def score(model):\n",
    "        cvscore = cross_val_score(\n",
    "            model,  # which model to use\n",
    "            X_train, y_train,  # what training data to split up\n",
    "            cv=k)  # number of folds/chunks\n",
    "        return np.mean(cvscore)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_train = X_train.copy()  # shallow copy\n",
    "    baseline = score(model)\n",
    "    imp = []\n",
    "    for col in X_train.columns:\n",
    "        print(col)\n",
    "        save = X_train[col].copy()\n",
    "        X_train[col] = np.random.permutation(X_train[col])\n",
    "        m = score(model)\n",
    "        X_train[col] = save\n",
    "        imp.append(baseline - m)\n",
    "\n",
    "    I = pd.DataFrame(data={'Feature': X_train.columns, 'Importance': np.array(imp)})\n",
    "    I = I.set_index('Feature')\n",
    "    I = I.sort_values('Importance', ascending=False)\n",
    "    return I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "RUGCJ3LKVGao",
    "outputId": "f03b443e-8ba8-4e53-d9c8-2b023feed4e4"
   },
   "outputs": [],
   "source": [
    "imp = cv_importances(svr_1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8pdMVH4vpT0"
   },
   "outputs": [],
   "source": [
    "coeffs = np.polyfit(x=y_test, y=y_pred, deg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5j22HfGvy6w"
   },
   "outputs": [],
   "source": [
    "m = coeffs[0] # Slope of the regression line y_pred = m*y_true+b. \n",
    "b = coeffs[1] # Independent term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "liytpL9Vwrvo"
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-86o-w29wta1"
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSRjsnNdGUEn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tF2GfXDrxJCw"
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmK5XTcswt9I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "applySVRwithbestparameters.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
